{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inverse heat equation with space dependent diffusion $D$\n",
    "========================================================\n",
    "In this example we want to solve an inverse problem where the parameter we are looking for is also a function.\n",
    "We consider, $\\Omega = [0, 10] \\times [0, 10]$ and:\n",
    "\\begin{align*}\n",
    " \\text{div}(D(x)\\nabla u(x, t)) &= \\partial_t u(x, t) \\text{ in } \\Omega \\times [0, 5]\\\\\n",
    " u(x, 0) &= 100\\sin(\\tfrac{\\pi}{10}x_1)\\sin(\\tfrac{\\pi}{10}x_2)  \\text{ in } \\Omega \\\\\n",
    " u(x, t) &= 0 \\text{ on } \\partial \\Omega \\times [0, 5]\n",
    "\\end{align*}  \n",
    "The diffusion will be given by: $D(x)=5e^{-\\tfrac{1}{20}((x_1-3)^2 + (x_2-3)^2)}$. \n",
    "\n",
    "With an external program, we computed a FEM solution of this equation. The data can be found under the data folder.\n",
    "This forward solution will be used as input data for the inverse problem.\n",
    "\n",
    "Since $D$ is a function too, we will use two neural networks. One for the temperature $u$ and for $D$. They will be connected over the PDE.\n",
    "\n",
    "This is the same example as in the folder examples/pinn, but in the second part of the notebook, the inverse problem is solved in Modulus with the wrapper module of TorchPhysics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchphysics as tp\n",
    "import pytorch_lightning as pl\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spaces and domains are defined like always:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tp.spaces.R2('x')\n",
    "T = tp.spaces.R1('t')\n",
    "\n",
    "D = tp.spaces.R1('D')\n",
    "U = tp.spaces.R1('u')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h = 10, 10\n",
    "t_0, t_end = 0, 5\n",
    "\n",
    "domain_x = tp.domains.Parallelogram(X, [0, 0], [w, 0], [0, h])\n",
    "domain_t = tp.domains.Interval(T, t_0, t_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we now have two networks, like previously mentioned.\n",
    "In the PDE both networks have to be evaluated, therefore we use the parallel evaluation of ``tp.models.Parallel``.\n",
    "This objects will evaluate all models in parallel and pass the output to the corresponding condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_u = tp.models.Sequential(\n",
    "            tp.models.NormalizationLayer(domain_x*domain_t),\n",
    "            tp.models.FCN(input_space=X*T, output_space=U, hidden=(80,80,50,50)))\n",
    "model_D = tp.models.Sequential(\n",
    "            tp.models.NormalizationLayer(domain_x),\n",
    "            tp.models.FCN(input_space=X, output_space=D, hidden=(80,80,50,50))) # D only has X as an Input\n",
    "parallel_model = tp.models.Parallel(model_u, model_D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load the data of the forward problem. There are around, 90000 data points, we take only some random ones of them. This is chosen with ``num_of_data ``. \n",
    "The data is in the form: [time, x-coordinates, temperature].\n",
    "\n",
    "After we have picked some points, we transform them to a ``Points``-object, so we can use the data in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "solution_data = np.load('data/heat-eq-inverse-data.npy')\n",
    "num_of_data = 30000\n",
    "solution_data = solution_data[np.random.choice(len(solution_data), num_of_data, replace=False), :].astype(np.float32)\n",
    "solution_data = torch.tensor(solution_data)\n",
    "inp_data = tp.spaces.Points.from_coordinates({'x': solution_data[:, 1:3], 't': solution_data[:, :1]})\n",
    "out_data = tp.spaces.Points.from_coordinates({'u': solution_data[:, 3:]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data will be put in a ``PointsDataLoader``, that will pass the data to the condition. \n",
    "As a condition, we will here use a ``DataCondition`` that just compares the output of the model with the expected values.\n",
    "\n",
    "In this condition, we only train the model of temperature, since we only have data of the temperature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = tp.utils.PointsDataLoader((inp_data, out_data), batch_size=num_of_data)\n",
    "data_condition = tp.conditions.DataCondition(module=model_u,\n",
    "                                             dataloader=data_loader,\n",
    "                                             norm=2, \n",
    "                                             use_full_dataset=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the differential equation we have to create some points inside the domain and check there the PDE.\n",
    "Here, both models will be used, since $D$ and $u$ have to fulfill this condition together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_sampler = tp.samplers.RandomUniformSampler(domain_x*domain_t, n_points=15000)\n",
    "\n",
    "def heat_residual(u, x, t, D):\n",
    "    return tp.utils.div(D*tp.utils.grad(u, x), x) - tp.utils.grad(u, t)\n",
    "\n",
    "pde_condition = tp.conditions.PINNCondition(module=parallel_model, # use parallel evaluation\n",
    "                                            sampler=inner_sampler,\n",
    "                                            residual_fn=heat_residual,\n",
    "                                            name='pde_condition', \n",
    "                                            weight=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is all we have to do. In total, the definition is not much different from the inverse problem with a constant $D$. Now we can start the training:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Training with TorchPhysics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = tp.OptimizerSetting(optimizer_class=torch.optim.Adam, lr=0.001)\n",
    "\n",
    "solver = tp.solver.Solver([pde_condition, data_condition])\n",
    "\n",
    "trainer = pl.Trainer(devices=1, accelerator=\"gpu\",\n",
    "                     max_steps=200,#8000,\n",
    "                     logger=True,\n",
    "                     benchmark=True,\n",
    "                     enable_checkpointing=False\n",
    "                    )                    \n",
    "                     \n",
    "trainer.fit(solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = tp.OptimizerSetting(optimizer_class=torch.optim.LBFGS, lr=0.5, \n",
    "                            optimizer_args={'max_iter': 2, 'history_size': 100})\n",
    "\n",
    "# make sampler static.\n",
    "pde_condition.sampler = pde_condition.sampler.make_static()\n",
    "\n",
    "solver = tp.solver.Solver([pde_condition, data_condition], optimizer_setting=optim)\n",
    "\n",
    "trainer = pl.Trainer(devices=1, accelerator=\"gpu\",\n",
    "                     max_steps=200,#10000, # number of training steps\n",
    "                     logger=True,\n",
    "                     benchmark=True,\n",
    "                     enable_checkpointing=False)\n",
    "                     \n",
    "trainer.fit(solver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can have look at the learned diffusion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sampler = tp.samplers.PlotSampler(plot_domain=domain_x, n_points=760, device='cuda')\n",
    "fig = tp.utils.plot(model_D, lambda D : D, plot_sampler, plot_type='contour_surface')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the exact function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact(x):\n",
    "    return 5*torch.exp(-1/20.0 * ((x[:, :1] - 3)**2 + (x[:, 1:] - 3)**2))\n",
    "\n",
    "fig = tp.utils.plot(model_D, exact, plot_sampler, plot_type='contour_surface')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the absolute error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(D, x):\n",
    "    return torch.abs(5*torch.exp(-1/20.0 * ((x[:, :1] - 3)**2 + (x[:, 1:] - 3)**2)) - D)\n",
    "\n",
    "fig = tp.utils.plot(model_D, error, plot_sampler, plot_type='contour_surface')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim_sampler = tp.samplers.AnimationSampler(domain_x, domain_t, 200, n_points=760)\n",
    "fig, anim = tp.utils.animate(model_u, lambda u: u, anim_sampler, ani_speed=10, ani_type='contour_surface')\n",
    "anim.save('inverse-heat-eq.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Training with the TorchPhysics wrapper in Modulus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to do the training in Modulus with the usage of the TPModulusWrapper.\n",
    "\n",
    "Remember that an additional Modulus installation is required!\n",
    "\n",
    "First, new initialization of the model and the conditions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_u = tp.models.Sequential(\n",
    "            tp.models.NormalizationLayer(domain_x*domain_t),\n",
    "            tp.models.FCN(input_space=X*T, output_space=U, hidden=(80,80,50,50)))\n",
    "model_D = tp.models.Sequential(\n",
    "            tp.models.NormalizationLayer(domain_x),\n",
    "            tp.models.FCN(input_space=X, output_space=D, hidden=(80,80,50,50))) # D only has X as an Input\n",
    "parallel_model = tp.models.Parallel(model_u, model_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = tp.utils.PointsDataLoader((inp_data, out_data), batch_size=num_of_data)\n",
    "data_condition = tp.conditions.DataCondition(module=model_u,\n",
    "                                             dataloader=data_loader,\n",
    "                                             norm=2, \n",
    "                                             use_full_dataset=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the Modulus losses are different from the TorchPhysics losses, we don't add an additional weight for the pde_condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_sampler = tp.samplers.RandomUniformSampler(domain_x*domain_t, n_points=15000)\n",
    "\n",
    "def heat_residual(u, x, t, D):\n",
    "    return tp.utils.div(D*tp.utils.grad(u, x), x) - tp.utils.grad(u, t)\n",
    "\n",
    "pde_condition = tp.conditions.PINNCondition(module=parallel_model, # use parallel evaluation\n",
    "                                            sampler=inner_sampler,\n",
    "                                            residual_fn=heat_residual,\n",
    "                                            name='pde_condition')\n",
    "                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = tp.OptimizerSetting(optimizer_class=torch.optim.Adam, lr=0.001)\n",
    "\n",
    "solver = tp.solver.Solver([pde_condition, data_condition])\n",
    "\n",
    "trainer = pl.Trainer(devices=1, accelerator=\"gpu\",\n",
    "                     max_steps=200,#8000,\n",
    "                     logger=True,\n",
    "                     benchmark=True,\n",
    "                     enable_checkpointing=False\n",
    "                    )                   \n",
    "\n",
    "tp.wrapper.TPModulusWrapper(trainer,solver).train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use LBFGS with the wrapper (Modulus), the max_steps has to be set to 1, the number of iterations are set by max_iter!\n",
    "As it one main iteration step, there is no output in between the max_iter iterations - iteration takes several minutes. Reduce max_iter for testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = tp.OptimizerSetting(optimizer_class=torch.optim.LBFGS, lr=0.5, \n",
    "                            optimizer_args={'max_iter': 200,#10000,     # number of training steps\n",
    "                             'history_size': 100})\n",
    "\n",
    "# make sampler static.\n",
    "pde_condition.sampler = pde_condition.sampler.make_static()\n",
    "\n",
    "solver = tp.solver.Solver([pde_condition, data_condition], optimizer_setting=optim)\n",
    "\n",
    "trainer = pl.Trainer(devices=1, accelerator=\"gpu\",\n",
    "                     max_steps=1, \n",
    "                     logger=True,\n",
    "                     benchmark=True,\n",
    "                     enable_checkpointing=False)\n",
    "\n",
    "tp.wrapper.TPModulusWrapper(trainer,solver).train()                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sampler = tp.samplers.PlotSampler(plot_domain=domain_x, n_points=760, device='cuda')\n",
    "fig = tp.utils.plot(model_D, lambda D : D, plot_sampler, plot_type='contour_surface')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(D, x):\n",
    "    return torch.abs(5*torch.exp(-1/20.0 * ((x[:, :1] - 3)**2 + (x[:, 1:] - 3)**2)) - D)\n",
    "\n",
    "fig = tp.utils.plot(model_D, error, plot_sampler, plot_type='contour_surface')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim_sampler = tp.samplers.AnimationSampler(domain_x, domain_t, 200, n_points=760)\n",
    "fig, anim = tp.utils.animate(model_u, lambda u: u, anim_sampler, ani_speed=10, ani_type='contour_surface')\n",
    "anim.save('inverse-heat-eq-wrapper.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
