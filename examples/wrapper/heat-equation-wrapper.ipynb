{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PINN: Heat equation with variable diffusion\n",
    "Solving the heat equation in 2D for variable diffusion D using the PINN-concept.\n",
    "\n",
    "This is the same example as in the folder examples/pinn, but in the second part of the notebook, the problem is solved in Modulus with the wrapper module of TorchPhysics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchphysics as tp\n",
    "import pytorch_lightning as pl\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create the spaces for our problem. These define the variable names which will be used in the remaining part of this code.\n",
    "\n",
    "In this example, x is the space variable, t corresponds to the time, D is an interval of diffusions and u is the variable for the (1D-)solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tp.spaces.R2('x')\n",
    "T = tp.spaces.R1('t')\n",
    "D = tp.spaces.R1('D')\n",
    "\n",
    "U = tp.spaces.R1('u')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a next step, we build the domain of the problem. There are multiple options to build multi-dimensional domains - in this case, we simply create a rectangle in space and intervals in time and diffusion which will later be multiplied to obtain the cartesian product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = 20, 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_x = tp.domains.Parallelogram(X, [0, 0], [w, 0], [0, h])\n",
    "A_t = tp.domains.Interval(T, 0, 40)\n",
    "A_D = tp.domains.Interval(D, 0.1, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we visualize the created domain, we create Sampler objects which are iterators that sample points from the domain during the optimization task. There are again various options to sample from the domains, an easy way would be to sample uniformly distributed random points. In this example, we choose an adaptive sampler to sample points in the inner of the domain. It will sample more points in points where the loss is large.\n",
    "\n",
    "The amount of sampled points is defined by their density in the 3/2-dim subset, it could be increased to achieve better training results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_sampler = tp.samplers.AdaptiveRandomRejectionSampler(A_x*A_t*A_D, density=1)\n",
    "# initial values should be sampled on the left boundary of the time interval and for every x and D\n",
    "initial_v_sampler = tp.samplers.RandomUniformSampler(A_x*A_t.boundary_left*A_D, density=1)\n",
    "\n",
    "boundary_v_sampler = tp.samplers.RandomUniformSampler(A_x.boundary*A_t*A_D, density=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize the domain through the points created by the samplers using matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = tp.utils.scatter(X*T, inner_sampler, initial_v_sampler, boundary_v_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step we define the NN-model we want to fit to the PDE. A normalization can improve convergence for large or small domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tp.models.Sequential(\n",
    "    tp.models.NormalizationLayer(A_x*A_t*A_D),\n",
    "    tp.models.FCN(input_space=X*T*D, output_space=U, hidden=(50,50,50))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we define a condition which aims to minimze the mean squared error of the residual of the poisson equation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heat_residual(u, x, t, D):\n",
    "    return D*tp.utils.laplacian(u, x) - tp.utils.grad(u, t)\n",
    "\n",
    "pde_condition = tp.conditions.PINNCondition(module=model,\n",
    "                                            sampler=inner_sampler,\n",
    "                                            residual_fn=heat_residual,\n",
    "                                            name='pde_condition')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we add a boundary condition at the boundary of the domain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundary_v_residual(u):\n",
    "    return u\n",
    "\n",
    "boundary_v_condition = tp.conditions.PINNCondition(module=model,\n",
    "                                                     sampler=boundary_v_sampler,\n",
    "                                                     residual_fn=boundary_v_residual,\n",
    "                                                     name='boundary_condition')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial condition can be defined via a data function. Again, we minimize the mean squared error over the sampled points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return torch.sin(math.pi/w*x[:, :1])*torch.sin(math.pi/h*x[:,1:])\n",
    "\n",
    "def initial_v_residual(u, f):\n",
    "    return u-f\n",
    "\n",
    "initial_v_condition = tp.conditions.PINNCondition(module=model,\n",
    "                                                  sampler=initial_v_sampler,\n",
    "                                                  residual_fn=initial_v_residual,\n",
    "                                                  data_functions={'f': f},\n",
    "                                                  name='initial_condition')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, we compute the solution via a finite difference scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from fdm_heat_equation import FDM, transform_to_points\n",
    "\n",
    "fdm_domain, fdm_time_domains, fdm_solution = FDM([0, w, 0, h], 2*[2e-1], [0,5], [0.1,0.2,0.4,0.6,0.8, 1.0], f)\n",
    "fdm_inp, fdm_out = transform_to_points(fdm_domain, fdm_time_domains, fdm_solution, [0.1,0.2,0.4,0.6,0.8, 1.0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparsion to measured or computed data can be performed via a DataCondition using data supplied via a PointsDataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_condition = tp.conditions.DataCondition(module=model,\n",
    "                                            dataloader=tp.utils.PointsDataLoader((fdm_inp, fdm_out), batch_size=80000),\n",
    "                                            norm='inf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Training in TorchPhysics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we optimize the conditions using a pytorch-lightning.LightningModule Solver and running the training. In the Solver, the training and validation conditions, as well as all optimizer options can be specified.\n",
    "\n",
    "The process of the training can be monitored with Tensorboard (e.g. tensorboard --logdir=lightning_logs --port=0). The losses are plotted under the tab \"SCALARS\" and the plots of the PlotterCallback can be found in the tab \"IMAGES\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decay_rate = 0.95\n",
    "decay_steps = 15000\n",
    "optim_setting = tp.solver.OptimizerSetting(torch.optim.Adam, lr=0.001,\n",
    "                            scheduler_class=torch.optim.lr_scheduler.ExponentialLR,\n",
    "                            scheduler_args={\"gamma\": decay_rate ** (1.0 / decay_steps)})\n",
    "\n",
    "solver = tp.solver.Solver([pde_condition,\n",
    "                           boundary_v_condition,\n",
    "                           initial_v_condition], [val_condition],\n",
    "                           optimizer_setting=optim_setting)\n",
    "\n",
    "run_name ='Heat_equation_paramD'\n",
    "\n",
    "plot_sampler = tp.samplers.PlotSampler(plot_domain=A_x, n_points=1000,device='cpu', data_for_other_variables={'D':1.0, 't': 5})\n",
    "callbacks = [  tp.utils.PlotterCallback(model=model,plot_function=lambda u: u[:,0],point_sampler=plot_sampler, \n",
    "                                         plot_type='contour_surface',log_name=run_name, check_interval=50),                 \n",
    "                \n",
    "                pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "            ]\n",
    "\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(devices=1, accelerator=\"gpu\",\n",
    "                     max_steps = 200,                     \n",
    "                     benchmark=True,            \n",
    "                     val_check_interval=40,\n",
    "                     enable_checkpointing=False,\n",
    "                     callbacks = callbacks\n",
    "                    )\n",
    "\n",
    "trainer.fit(solver)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we plot the obtained solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim_sampler = tp.samplers.AnimationSampler(A_x, A_t, 100, n_points=400, data_for_other_variables={'D': 1.0})\n",
    "anim = tp.utils.animate(model, lambda u: u[:, 0], anim_sampler, ani_speed=10)\n",
    "anim[1].save('heat-eq.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Training with the wrapper in Modulus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to do the training in Modulus with the usage of the TPModulusWrapper.\n",
    "\n",
    "Remember that an additional Modulus installation is required!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a Modulus Fourier net architecture with the ModulusArchitectureWrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tp.models.Sequential(\n",
    "    tp.models.NormalizationLayer(A_x*A_t*A_D),    \n",
    "    tp.wrapper.ModulusArchitectureWrapper(input_space=X*T*D, output_space=U, arch_name='fourier', frequencies = ['axis',[0,1,2]])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New initialization of the same conditions as before.\n",
    "\n",
    "Since Modulus by default saves the resulting values of the condition objectives and validation in VTK-files, the training procedure will slow down, when the amount of validation data increase or if the frequency of validation (val_check_interval) or the plotter callback frequency (check_interval) is too high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pde_condition = tp.conditions.PINNCondition(module=model,\n",
    "                                            sampler=inner_sampler,\n",
    "                                            residual_fn=heat_residual,\n",
    "                                            name='pde_condition')\n",
    "boundary_v_condition = tp.conditions.PINNCondition(module=model,\n",
    "                                                     sampler=boundary_v_sampler,\n",
    "                                                     residual_fn=boundary_v_residual,\n",
    "                                                     name='boundary_condition')\n",
    "initial_v_condition = tp.conditions.PINNCondition(module=model,\n",
    "                                                  sampler=initial_v_sampler,\n",
    "                                                  residual_fn=initial_v_residual,\n",
    "                                                  data_functions={'f': f},\n",
    "                                                  name='initial_condition')\n",
    "val_condition = tp.conditions.DataCondition(module=model,\n",
    "                                            dataloader=tp.utils.PointsDataLoader((fdm_inp, fdm_out), batch_size=80000),\n",
    "                                            norm='inf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning rate monitor callback could be omitted here, as Modulus uses it by default.\n",
    "\n",
    "The process of the training can be monitored again with tensorboard, but in this example with --logdir=outputs_heat, as this is the name of the folder containing the Modulus output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decay_rate = 0.95\n",
    "decay_steps = 15000\n",
    "optim_setting = tp.solver.OptimizerSetting(torch.optim.Adam, lr=0.001,\n",
    "                            scheduler_class=torch.optim.lr_scheduler.ExponentialLR,\n",
    "                            scheduler_args={\"gamma\": decay_rate ** (1.0 / decay_steps)})\n",
    "\n",
    "solver = tp.solver.Solver([pde_condition,\n",
    "                           boundary_v_condition,\n",
    "                           initial_v_condition], \n",
    "                          [val_condition],\n",
    "                           optimizer_setting=optim_setting)\n",
    "\n",
    "run_name ='Heat_equation_paramD_Modulus'\n",
    "\n",
    "plot_sampler = tp.samplers.PlotSampler(plot_domain=A_x, n_points=1000,device='cpu', data_for_other_variables={'D':1.0, 't': 5})\n",
    "callbacks = [  tp.utils.PlotterCallback(model=model,plot_function=lambda u: u[:,0],point_sampler=plot_sampler, \n",
    "                                         plot_type='contour_surface',log_name=run_name, check_interval=50),                 \n",
    "                \n",
    "                pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "            ]\n",
    "\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(devices=1, accelerator=\"gpu\",\n",
    "                     max_steps = 200,                     \n",
    "                     benchmark=True,            \n",
    "                     val_check_interval=40,\n",
    "                     enable_checkpointing=False,\n",
    "                     callbacks = callbacks\n",
    "                    )\n",
    "\n",
    "\n",
    "tp.wrapper.TPModulusWrapper(trainer,solver,confdir_name='conf_heat',outputdir_name='outputs_heat').train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim_sampler = tp.samplers.AnimationSampler(A_x, A_t, 100, n_points=400, data_for_other_variables={'D': 1.0})\n",
    "anim = tp.utils.animate(model, lambda u: u[:, 0], anim_sampler, ani_speed=10)\n",
    "anim[1].save('heat-eq-wrapper.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are addtional options for the training with the wrapper, e.g. use of aggregating function like LR Annealing or using spatial loss weighting, e.g. with the signed distance function. \n",
    "For further information use the help function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(tp.wrapper.TPModulusWrapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with the use of LR Annealing and the sdf function for spatial weighting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.wrapper.TPModulusWrapper(trainer,solver,lambda_weighting=[\"sdf\"],aggregator='LRAnnealing',confdir_name='conf_heat',outputdir_name='outputs_heat').train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
